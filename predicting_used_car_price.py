# -*- coding: utf-8 -*-
"""Predicting Used Car Price

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dlaBuCEVnz2d5yTG_BVdBLD3eiG9rmi4

This project is part of training in Bangkit Academy.

We use data from Kaggle - "Used cars database".

We try to predict 'Price' based on 'PowerPS'.

Our Filtering Data:
1. We only use SUV type 
2. We try to only use Mercedes-Bens Cars

We use SUV and Mercedes-Bens because that the most top selling car, and with same brand, easier to predict.

We use code experiment from Machine Learning Crash Course by Google.

Our Team Members:
1. Yohanes
2. Eko
3. Yogic

Here the step by step and code bellow
"""

# Commented out IPython magic to ensure Python compatibility.
#Run on TensorFlow 2.x
# %tensorflow_version 2.x

#Import relevant modules
import pandas as pd
import tensorflow as tf
from matplotlib import pyplot as plt

# The following lines adjust the granularity of reporting. 
pd.options.display.max_rows = 10
pd.options.display.float_format = "{:.1f}".format

# Import the dataset.
#training_df = pd.read_csv(filepath_or_buffer="https://drive.google.com/file/d/1RbuaM4QrjRrSIXvvsUdGanY7TpHXDVYj/view?usp=sharing")
training_df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vTkbsvshuhRMeir109MvC_3QvbpJwBJkMN9R0KeCWehSzu74CoU29Nlf11klUkdHWfSoH81HHkbxtru/pub?output=csv')


# Print the first rows of the pandas DataFrame.
training_df.head()

# Get statistics on the dataset.
training_df.describe()

# Define the functions that build and train a model
def build_model(my_learning_rate):
  """Create and compile a simple linear regression model."""
  # Most simple tf.keras models are sequential.
  model = tf.keras.models.Sequential()

  # Describe the topography of the model.
  # The topography of a simple linear regression model
  # is a single node in a single layer.
  model.add(tf.keras.layers.Dense(units=1, 
                                  input_shape=(1,)))

  # Compile the model topography into code that TensorFlow can efficiently
  # execute. Configure training to minimize the model's mean squared error. 
  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),
                loss="mean_squared_error",
                metrics=[tf.keras.metrics.RootMeanSquaredError()])

  return model        


def train_model(model, df, feature, label, epochs, batch_size):
  """Train the model by feeding it data."""

  # Feed the model the feature and the label.
  # The model will train for the specified number of epochs. 
  history = model.fit(x=df[feature],
                      y=df[label],
                      batch_size=None,
                      epochs=epochs)

  # Gather the trained model's weight and bias.
  trained_weight = model.get_weights()[0]
  trained_bias = model.get_weights()[1]

  # The list of epochs is stored separately from the rest of history.
  epochs = history.epoch
  
  # Isolate the error for each epoch.
  hist = pd.DataFrame(history.history)

  # To track the progression of training, we're going to take a snapshot
  # of the model's root mean squared error at each epoch. 
  rmse = hist["root_mean_squared_error"]

  return trained_weight, trained_bias, epochs, rmse

print("Defined the create_model and traing_model functions.")

# Define the plotting functions
def plot_the_model(trained_weight, trained_bias, feature, label, largest_value):
  """Plot the trained model against 200 random training examples."""

  # Label the axes.
  plt.xlabel(feature)
  plt.ylabel(label)

  # Create a scatter plot from 200 random points of the dataset.
  random_examples = training_df.sample(n=60)
  plt.scatter(random_examples[feature], random_examples[label])

  # Create a red line representing the model. The red line starts
  # at coordinates (x0, y0) and ends at coordinates (x1, y1).
  x0 = 0
  y0 = trained_bias
  x1 = largest_value
  y1 = trained_bias + (trained_weight * x1)
  plt.plot([x0, x1], [y0, y1], c='r')

  # Render the scatter plot and the red line.
  plt.show()


def plot_the_loss_curve(epochs, rmse):
  """Plot a curve of loss vs. epoch."""

  plt.figure()
  plt.xlabel("Epoch")
  plt.ylabel("Root Mean Squared Error")

  plt.plot(epochs, rmse, label="Loss")
  plt.legend()
  plt.ylim([rmse.min()*0.97, rmse.max()])
  plt.show()  

print("Defined the plot_the_model and plot_the_loss_curve functions.")

# Testing Corelation between households and total_rooms.

# Selecting label and feature
my_feature = "price"
my_label= "powerPS" 

# Assign values to these three hyperparameters.
learning_rate = 0.01
epochs = 100
batch_size =  60

# Don't change anything below this line.
my_model = build_model(learning_rate)
weight, bias, epochs, rmse = train_model(my_model, training_df,
                                         my_feature, my_label,
                                         epochs, batch_size)

plot_the_model(weight, bias, my_feature, my_label,100000)
plot_the_loss_curve(epochs, rmse)

"""Conclusion:
1. This is our first experiment using real data from kaggle.
2. We saw that PowerPS have corellation with Price.

Task Further:
1. Examine data to find another Relationship
2. Try to use larger data
3. Split into training dataset and test dataset
4. Do Validation Test
"""